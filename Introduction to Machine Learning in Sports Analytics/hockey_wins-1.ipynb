{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00000-ad337d62-e090-4fb1-aa2d-5e77e881dc78",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "9ba04ce60253fb7d7f70ba8adf1cfc0b1939a5f87dc1badb1ae359f9fe184aaa",
    "execution_millis": 2,
    "execution_start": 1621190244006,
    "source_hash": "5a7e589d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First let's bring in a few imports. Since we need to scrape some web data I'm going to bring in the\n",
    "# urllib and json libraries\n",
    "import urllib3\n",
    "import json\n",
    "import itertools\n",
    "\n",
    "# And the standard data science data manipulation imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# The goal in this case is to predict the winner or loser of a given match using logistic regression. For\n",
    "# the time being I am going to take out ties. Concepturally our feature set will include three things, the\n",
    "# performance of the two teams (home and away) based on their statistics this season so far, the salary cap\n",
    "# for the teams which is an indicator of the value of players (one would think teams which pay more will\n",
    "# have stronger players earning that money), and the standings of the teams (again, home and away) from the\n",
    "# previous season.\n",
    "\n",
    "# Take note of the temporal nature of some of this data -- as we gain more information about the season our\n",
    "# machine learning model should be able to better predict the immediate future. Also, we use last season's\n",
    "# stats to help incorporate prior knowledge, but we could look back at several seasons and this would effect\n",
    "# the model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00001-32eed2ea-e8ff-40a6-bd50-1e1099b61e6f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "184d22d8d5da7527218f5aeaac7d7a307737138e6dc236b059297dd23d97441e",
    "execution_millis": 68499,
    "execution_start": 1621190244013,
    "source_hash": "b6cbafbe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # First step is that I want to write a function to retrieve data from the wonderful NHL APIs which\n",
    "# # are available directly from the NHL. In this case we're going to build a model for the 2017-2018\n",
    "# # season. This season had 1,271 games in it\n",
    "\n",
    "# def get_game_data(gameid=1):\n",
    "#     '''Retrieves individual game data and creates a DataFrame of the home and away teams and their\n",
    "#     score results. This function assumes we are interested in the season 2017 and that we want\n",
    "#     only regular season games.\n",
    "\n",
    "#     :param gameid: The game number to retrieve data from.\n",
    "#     '''\n",
    "#     # We can pull down the JSON data directly from the NHL API\n",
    "#     game_url=f'https://statsapi.web.nhl.com/api/v1/game/201702{str(gameid).zfill(4)}/feed/live'\n",
    "#     http = urllib3.PoolManager()\n",
    "#     r = http.request('GET', game_url)\n",
    "#     data=json.loads(r.data)\n",
    "\n",
    "#     # The JSON data is pretty rich. For this analysis we want to get information on scoring which\n",
    "#     # is in the goals JSON object\n",
    "#     results=data['liveData']['plays']['currentPlay']['about']['goals']\n",
    "\n",
    "#     # We also need to get information on the home and away team names. This isn't useful for our\n",
    "#     # model per se, since we want to predict just whether the home team or the away team will win,\n",
    "#     # but we need this in order to connect to our other data sources\n",
    "#     teams={'home_team': data['gameData']['teams']['home']['name'], 'away_team': data['gameData']['teams']['away']['name']}\n",
    "\n",
    "#     # And we'll include when the game happened\n",
    "#     time={'time': data['metaData']['timeStamp']}\n",
    "\n",
    "#     # Now we can just bring these three dictionaries together. This might be unfamiliar syntax, \n",
    "#     # it's called dictionary unpacking, but it just breaks each dictionary up and creates a new\n",
    "#     # dictionary which combines them all. In the end we want to work with pandas DataFrame objects\n",
    "#     # so that's what we can return to the caller (indexed by the time of the game)\n",
    "#     row={**results,**teams,**time}\n",
    "#     return pd.DataFrame(row, index=[row[\"time\"]])\n",
    "\n",
    "# # Commented out for Coursera, you can uncomment the code below if you are running locally.\n",
    "# # Now let's just call this function for every game in the season, 1 through 1,271\n",
    "# # game_results=pd.concat( [get_game_data(x) for x in range(1,1271)] )\n",
    "\n",
    "# # And now that we've pulled this down, I'm going to save it for offline use\n",
    "# # game_results.to_csv(\"assets/game_results.csv\")\n",
    "\n",
    "# # And let's take a look at that DataFrame\n",
    "# # game_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00002-ef388c5c-6ad2-4914-87c5-f0acb20fd0d0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "e53bd9ddedf8aa71597fca28bfaf2ae38cd4cb081de4f0a7cfc5699899ad20eb",
    "execution_millis": 30,
    "execution_start": 1621190312506,
    "source_hash": "4c598fca",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If you are on coursera, you'll want to load the datafile\n",
    "game_results=pd.read_csv(\"game_results.csv\",index_col=0)\n",
    "game_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_results[\"home_team\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_results[\"away_team\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_results[game_results[\"home_team\"].str.contains(\"Vegas Golden Knights\") == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = game_results[game_results[\"home_team\"].str.contains(\"Vegas Golden Knights\") == False]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"home_team\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"away_team\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df[\"away_team\"].str.contains(\"Vegas Golden Knights\") == False]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_results = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00002-203437a3-25e9-4715-9c30-dd25f0b56bc1",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "df9e65e191257388dd5c9a553897b59b7b2a878b4140ca3a2bcc42e52fed9fd0",
    "execution_millis": 40,
    "execution_start": 1621190312533,
    "source_hash": "8796d3da",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# So this includes our game-by-game breakdown of the season. We need to add a new column which\n",
    "# indicates which team won, either home or away. We can do this by setting the default winner to\n",
    "# away then looking at the game scores and flipping it to home where appropriate.\n",
    "game_results[\"outcome_categorical\"]=\"away\"\n",
    "game_results.loc[ (game_results[\"away\"]<game_results[\"home\"]), \"outcome_categorical\"]=\"home\"\n",
    "game_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_results.home_team.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_results.away_team.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00001-700f92a6-c632-428b-b80a-e101103362ce",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "08f2e254a3277c85eabd9d0d6235dfa48e934af897f0cbfd2c238ef0e7fc3cf3",
    "execution_millis": 200,
    "execution_start": 1621190312569,
    "source_hash": "35c80237",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Commented out for Coursera, you can uncomment the code below if you are running locally.\n",
    "\n",
    "# Now, let's bring in salary information. I'm going to pull this down from a website called\n",
    "# cap friendly. This website does not have an API, so we need to scrape it. Thankfully,\n",
    "# pandas has a function which aims to turn HTML tables into DataFrames for us automatically\n",
    "# called read_html(). The result of this function is a list of DataFrames, and I've manually\n",
    "# inspected this to see that there is only one which has all of our cap information.\n",
    "# salary=pd.read_html(\"https://www.capfriendly.com/archive/2017\")[0]\n",
    "\n",
    "# Now this website has pretty values of dollars, but we just want these as numeric values,\n",
    "# so I'm going to change our column of interest (the final cap hit) to be stripped of\n",
    "# commas and dollar signs\n",
    "# salary[\"FINAL CAP HIT\"]=salary[\"FINAL CAP HIT\"].str.replace(',', '').str.replace('$', '').astype(int)\n",
    "\n",
    "# Let's store this data to a file too\n",
    "# salary.to_csv(\"assets/salary.csv\",index=False)\n",
    "# salary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00005-a8b4fbe6-1080-4947-9256-b1c9f6c621bb",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "4b3e0f48e565e79d89688df0a7c4a3f3698dda276ffb80d35f17cf8ea99cf4a9",
    "execution_millis": 12,
    "execution_start": 1621190312790,
    "source_hash": "653b1cdf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If you are on coursera, you'll want to load the datafile\n",
    "salary = pd.read_csv(\"salary.csv\")\n",
    "salary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary[\"TEAM\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00004-7000016f-dee4-434d-b9a9-e77df5a69366",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "778e16087f721a730dbdc49d76eaa12261fbc2463535b8a8f8e0b46e4f0d7c81",
    "execution_millis": 30,
    "execution_start": 1621190312791,
    "source_hash": "b6a8938d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The dirty secret of data science and analytics is that most of the work is in obtaining\n",
    "# and cleaning data. It's good to build in some checks to see that all of the teams in our\n",
    "# salary data are actually in the game data we had. We can do this through a set difference.\n",
    "set( game_results[\"home_team\"].unique() ) - set( salary[\"TEAM\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00004-bf9bb5e1-f3b6-4a30-bacc-bc5b1d916bf2",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "3e17967dd28b3efed100e2d07e6805b122fd3cc9990b3bd148d4ea712e23b200",
    "execution_millis": 26,
    "execution_start": 1621190312795,
    "source_hash": "95c90a48",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ok, so there are two problem teams, the Canadiens and the Golden Knights. Now, as a die hard\n",
    "# Canadian who is also a strong Oilers fan I don't have a problem dropping the Canadiens from\n",
    "# our analysis completely, but it turns out my wife (a french Canadian) disagrees with this\n",
    "# so instead let's rename the team in our salary data\n",
    "salary[\"TEAM\"]=salary[\"TEAM\"].replace(\"Montreal Canadiens\",\"MontrÃ©al Canadiens\")\n",
    "\n",
    "# And I'm going to promote the team column to the index of the dataframe, and just get rid\n",
    "# of the columns we are not going to use\n",
    "salary=salary.set_index(\"TEAM\")\n",
    "salary=salary[\"FINAL CAP HIT\"]\n",
    "\n",
    "# The Golden Knights represent another important problem -- they didn't exist in the league\n",
    "# in the 2016 season, so they didn't have salary cap information. This is going to be a\n",
    "# problem when looking at their stats from the previous season too. I'm going to fill in their\n",
    "# data as missing using the numpy NaN values, but it turns out we'll have to address this\n",
    "# again later.\n",
    "#salary.loc['Vegas Golden Knights']=np.nan\n",
    "#salary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00002-327e69bc-f225-4271-ab3c-7f7b8a290b60",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "db37cedd972b23c2c2813fb9562cef585ca66287b94fa9d54db4ef0c0eb7602c",
    "execution_millis": 311,
    "execution_start": 1621190312812,
    "source_hash": "e2790b5b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Great, we have two data sources down and ready for analysis, now we need to get some prior\n",
    "# # information about teams from the previous season. This will be useful for our model when\n",
    "# # we want to make early predictions and don't have the current season data.\n",
    "\n",
    "# # The NHL API has another great place to get standings for a whole season, so we'll use that\n",
    "# def team_standings(season=\"20162017\"):\n",
    "#     '''Pull down the standings for teams in a single season.\n",
    "#     :param season: The season code (e.g. 20162017 for the 2016-2017 season)\n",
    "#     '''\n",
    "#     # Pull down the JSON data from the API directly\n",
    "#     game_url=f\"https://statsapi.web.nhl.com/api/v1/standings?season={season}\"\n",
    "#     http = urllib3.PoolManager()\n",
    "#     r = http.request('GET', game_url)\n",
    "#     data=json.loads(r.data)\n",
    "\n",
    "#     # In this case the JSON data has a record element for divisions and then lists the team \n",
    "#     # records inside of that, so we need to do a nested iteration\n",
    "#     df_standings=pd.DataFrame()\n",
    "#     for record in data[\"records\"]:\n",
    "#         for team_record in record[\"teamRecords\"]:\n",
    "\n",
    "#             # We have to decide which standings we want to incorporate. Do we want just the\n",
    "#             # rank of the team from last season? The number of games they won? The number of\n",
    "#             # goals scored? This is where your knowledge of the sport can come in to add\n",
    "#             # context and value. I'm going to just include everything - for now - but this\n",
    "#             # is usually a poor choice in practice.\n",
    "\n",
    "#             # Since this is a JSON structure, and we want to turn it into a DataFrame, we can\n",
    "#             # use the handy json_normalize() function in pandas to \"flatten\" the JSON. And\n",
    "#             # we can just add that DataFrame to the bottom of our df_standings\n",
    "#             df_standings=df_standings.append(pd.json_normalize(team_record))\n",
    "#     return df_standings\n",
    "\n",
    "# # Commented out for Coursera, you can uncomment the code below if you are running locally.\n",
    "# # previous_season_standings=team_standings()\n",
    "\n",
    "# # Let's save this for offline use\n",
    "# # previous_season_standings.to_csv(\"assets/previous_season_standings.csv\",index=False)\n",
    "# # previous_season_standings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00009-234ce20e-175f-4c5b-b700-d1e3150dd61f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "c4b1108502677fefa3d6a4b38f9c5d15b26cd8d9154cbdb33e50dc5e8ea2f241",
    "execution_millis": 84,
    "execution_start": 1621190313101,
    "source_hash": "c570e9ca",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If you are on coursera, you'll want to load the datafile\n",
    "previous_season_standings=pd.read_csv(\"previous_season_standings.csv\")\n",
    "previous_season_standings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_season_standings[\"team.name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00007-58c6e92d-3a75-4399-bba7-2784860799f0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "2fa4b7888f14abbbfc83c8b96db739a545e49e016ea2c9bf4a028286fa372250",
    "execution_millis": 143,
    "execution_start": 1621190313177,
    "source_hash": "90454e7c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ok, we have our three sources of data for features. First, we have an game by game breakdown\n",
    "# of teams and scores for this season in game_results, and our target column (the one we want\n",
    "# to predict) is outcome_categorical. We also have the salary information in the salary Series,\n",
    "# and we have last year's data in previous_season_standings. What we are missing, however, is\n",
    "# and cummulative knowledge about how the teams are performing in the season of interest. Our\n",
    "# game_results dataframe only has who won and the game time, but it doesn't tell use what the\n",
    "# stats are for each team thus far in the season. Of course, we would expect the stats for the\n",
    "# team this season to have the highest predictive power for an upcoming game, so we need to build\n",
    "# this cummulative DataFrame.\n",
    "\n",
    "# Let's create a new DataFrame with won and lost columns, and initialize it with the teams in\n",
    "# our game_results data and set the initial values to 0. We can incremend this as we gain new\n",
    "# evidence of game performance\n",
    "df_cum=pd.DataFrame()\n",
    "df_cum.loc['won', list(game_results[\"home_team\"].unique()) ]=0\n",
    "df_cum.loc['lost', list(game_results[\"home_team\"].unique()) ]=0\n",
    "\n",
    "# I'm going to use a bit more advanced pandas here in the form of a multi-index on columns by\n",
    "# calling unstack() and then adding a time row. This is just an entry for those default 0's\n",
    "# and we'll get rid of it after we have built the cumulative DataFrame\n",
    "df_cum=df_cum.unstack()\n",
    "df_cum=pd.DataFrame(df_cum,columns=['time']).T\n",
    "df_cum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00008-7c00ea86-ef15-4d9d-bb46-5c22a86464e3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "bff867799e338428333a8c34c4e9a03ace673071aeb680f172c852715ae7f057",
    "execution_millis": 1993,
    "execution_start": 1621190313317,
    "source_hash": "41acbae8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now we just need to iterate through all of the results in our game_results and calculate\n",
    "# the cummulative wins and losses as appropriate. Pandas provides a nice way to do this\n",
    "# using the iterrows() function\n",
    "for idx,row in game_results.iterrows():\n",
    "    # Identifying the winner and loser is pretty easy - remember we got rid of ties!\n",
    "    if row[\"away\"]>row[\"home\"]:\n",
    "        winner=row[\"away_team\"]\n",
    "        loser=row[\"home_team\"]\n",
    "    elif row[\"away\"]< row[\"home\"]:\n",
    "        winner=row[\"home_team\"]\n",
    "        loser=row[\"away_team\"]\n",
    "\n",
    "    # Now we just update the entry in our cumulative DataFrame. The syntax here might be\n",
    "    # a bit surprising because we have a multi-index on columns.\n",
    "    df_cum.loc[idx, (winner,\"won\")]=df_cum[(winner,\"won\")].max()+1\n",
    "    df_cum.loc[idx, (loser,\"lost\")]=df_cum[(loser,\"lost\")].max()+1\n",
    "\n",
    "# Let's see what we have\n",
    "df_cum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00009-312a63f5-0367-4367-8aee-a1168cdd6566",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "3369bc733e6f1b5ec1f494efae23813841f11036ab584cd6b403111cdda376d9",
    "execution_millis": 120,
    "execution_start": 1621190315300,
    "source_hash": "505ef0f5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Great, now let's propogate our scores forward in time, e.g. everyone gets a 0 until they\n",
    "# play their first game, and we can do this with the ffilna() function. We'll also drop that\n",
    "# first row of data (which we called time) since it's no longer needed.\n",
    "df_cum=df_cum.fillna(method='ffill').drop(index=\"time\")\n",
    "df_cum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00001-89896335-2c29-43f1-8f72-8326d947ff80",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "7acfd01af06c6e2059300ed5054ed01aed300f8965623423631ef87da2bdb5b4",
    "execution_millis": 8780,
    "execution_start": 1621190611609,
    "source_hash": "63bcbad1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ok, I'm getting excited, we're almost at the good part! Now we just need to turn these\n",
    "# three different data objects into a feature vector for prediction! Let's write another\n",
    "# function, and we can have this function operate on a single row of game_results data,\n",
    "# and pull from the other DataFrames to create a feature vector. \n",
    "def create_features(row):\n",
    "    '''Operates on a single row of data from game_results, and interacts with global\n",
    "    dataframes salary, previous_season_standings, and df_cum to generate a feature\n",
    "    vector for that row.\n",
    "    :param row: A single row in game_results\n",
    "    :param return: A feature vector as a pandas Series object\n",
    "    '''\n",
    "    # Inside of this function let's store our features in a dictionary\n",
    "    features={}\n",
    "\n",
    "    # We can start by looking up the number of games the home and away teams have lost thus\n",
    "    # far in the season\n",
    "    features[\"away_won\"]=df_cum.loc[row.name,(row[\"away_team\"],\"won\")]\n",
    "    features[\"away_lost\"]=df_cum.loc[row.name,(row[\"away_team\"],\"lost\")]\n",
    "    features[\"home_won\"]=df_cum.loc[row.name,(row[\"home_team\"],\"won\")]\n",
    "    features[\"home_lost\"]=df_cum.loc[row.name,(row[\"home_team\"],\"lost\")]\n",
    "\n",
    "    # We have to adjust this to ensure that we're not leaking the results of this match!\n",
    "    if row[\"outcome_categorical\"]==\"home\":\n",
    "        features[\"home_won\"]=features[\"home_won\"]-1\n",
    "        features[\"away_lost\"]=features[\"away_lost\"]-1\n",
    "    else:\n",
    "        features[\"home_lost\"]=features[\"home_lost\"]-1\n",
    "        features[\"away_won\"]=features[\"away_won\"]-1\n",
    "\n",
    "\n",
    "    # Let's add in the salary cap information from last year\n",
    "    features[\"away_cap\"]=salary[row[\"away_team\"]]\n",
    "    features[\"home_cap\"]=salary[row[\"home_team\"]]\n",
    "\n",
    "    # Let's get the previous season standings for each team too, and add an indicator\n",
    "    # to each standing whether it was for the home or away team\n",
    "    home_last_season=previous_season_standings.query(f\"`team.name`=='{row['home_team']}'\").add_prefix(\"home_last_season_\")\n",
    "    away_last_season=previous_season_standings.query(f\"`team.name`=='{row['away_team']}'\").add_prefix(\"away_last_season_\")\n",
    "\n",
    "    # Remember those Vegas Golden Knights? They didn't exist in the previous season, so\n",
    "    # our code to convert the values to a dictionary won't work. We need to be robust to\n",
    "    # this case, so let's just create an empty dictionary for teams which have no previous\n",
    "    # season\n",
    "    if len(home_last_season)>0:\n",
    "        home_last_season=home_last_season.iloc[0].to_dict()\n",
    "    else:\n",
    "        home_last_season={}\n",
    "    if len(away_last_season)>0:\n",
    "        away_last_season=away_last_season.iloc[0].to_dict()\n",
    "    else:\n",
    "        away_last_season={}\n",
    "\n",
    "    # Now we can leverage dictionary unpacking, returning all of the items including the\n",
    "    # data from the game_results (which has our target variable) as a new Series\n",
    "    return pd.Series({**features, **home_last_season, **away_last_season, **row})\n",
    "\n",
    "# Let's generate these game results and put them into a new DataFrame called observations\n",
    "observations=game_results.apply(create_features, axis='columns')\n",
    "observations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations[\"home_team\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations[\"away_team\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00004-7bff13fb-e04e-4568-b280-2f19bb95f144",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "1e6d1ba076f16dcea664d4fc1aa16c4a1ee1eaecff9cdc64675af81662bcc3a9",
    "execution_millis": 1,
    "execution_start": 1621190620381,
    "source_hash": "de3ce41c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ok, almost done with the data cleaning, now we have to go through and decide which\n",
    "# columns we want to include in our model. There are a few obvious ones, for instance\n",
    "# if we include the away and home scores in our model we should get a perfect\n",
    "# prediction since our outcome target is completely based on this information. So lets\n",
    "# get rid of those.\n",
    "observations=observations.drop([\"away\",\"home\"],axis='columns')\n",
    "\n",
    "# We're also going to get rid of team name too\n",
    "observations=observations.drop([\"away_team\",\"home_team\"],axis='columns')\n",
    "\n",
    "# In this example I'm just going to do a simple logistic regression, so some of the\n",
    "# non-numeric data like \"clinchIndicator\" can't be used without converting this to dummy\n",
    "# variables. Converting to dummy, or indicator, features is a reasonable choice, but\n",
    "# I'm going to aim for simplicty for this demonstration instead, and get rid of these\n",
    "# columns too\n",
    "observations=observations.drop(['away_last_season_clinchIndicator','away_last_season_lastUpdated',\n",
    "    'away_last_season_leagueRecord.type','away_last_season_streak.streakCode',\n",
    "    'away_last_season_streak.streakType','away_last_season_team.link','away_last_season_team.name',\n",
    "    'home_last_season_clinchIndicator','home_last_season_lastUpdated',\n",
    "    'home_last_season_leagueRecord.type','home_last_season_streak.streakCode',\n",
    "    'home_last_season_streak.streakType','home_last_season_team.link','home_last_season_team.name'],\n",
    "    axis='columns')\n",
    "\n",
    "# I made some pretty arbitrary and questionable choices here. For instance, I got rid of the\n",
    "# semantic information about streaks (e.g. whether they were winning or losing streaks), but I\n",
    "# left the numeric value for the length of the streak! This is not meaningful information\n",
    "# for our model anymore, as a team which had a great 5 game winning streak last year and one\n",
    "# which had a horrible 5 game losing streak will look the same.\n",
    "\n",
    "# In the end, the best model will be one which has clean and thoughtful data coming into it\n",
    "# where the data is indicative of future data, and we'll talk a bit about the principle of\n",
    "# parsimony in a future lecture.\n",
    "\n",
    "# One last bit of cleaning - let's get rid of the time column, it's just noise which we already\n",
    "# have captured in the index and won't be useful for our modeling approach\n",
    "observations=observations.drop(\"time\",axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00012-52b0615b-7003-488e-a2f7-a93c9f9cbcba",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "18aed84399472d51bc9e9cd77cce7d2cd3c13ec981df534ff35b03e5db838f6d",
    "execution_millis": 90,
    "execution_start": 1621190620385,
    "source_hash": "f7e6e515",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# With our observations cleaned we now face another choice: what to do with \n",
    "# missing values. Missing values are a signal of their own, but most machine learning\n",
    "# techniques want an explicit indication of what missing means. Strategies for numeric\n",
    "# values, which we have here, are usually aggregation functions based on the rest\n",
    "# of the data we have. For the Vegas Golden Knights, for instance, what should\n",
    "# we be expecting their performance from the last year was like? The average performance\n",
    "# of other teams? Worse than the bottom performing team, since the Golden Knights are\n",
    "# new? Again, this is a place you need to bring your understanding of the domain to\n",
    "# the process and set reasonable values. In this case, I'm going to fill all missing\n",
    "# values with the mean() value from other observations.\n",
    "\n",
    "# But, a moment of caution! Remember that we are working through the whole machine\n",
    "# learning pipeline here. So we are planning to build a model on some training data, and\n",
    "# then determine how well it works on some held out test data. We want to split up\n",
    "# our sets before we start replacing imputed data, so that we don't \"leak\" information\n",
    "# from our test set.\n",
    "\n",
    "# Let's first make sure all of our columns are numeric\n",
    "for col in observations.columns:\n",
    "    if col != 'outcome_categorical':\n",
    "        observations[col]=pd.to_numeric(observations[col])\n",
    "\n",
    "# And let's save this list of observations for use in the future\n",
    "observations.to_csv(\"observations.csv\")\n",
    "\n",
    "# Let's put the first 800 observations in our training data.\n",
    "training_df=observations[0:800]\n",
    "testing_df=observations[800:]\n",
    "\n",
    "# And now lets impute the missing data for each set independently\n",
    "training_df=training_df.fillna(training_df.mean())\n",
    "testing_df=testing_df.fillna(testing_df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = testing_df.drop('outcome_categorical', axis='columns')\n",
    "test_target = testing_df['outcome_categorical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=training_df.drop('outcome_categorical', axis='columns')\n",
    "target=training_df['outcome_categorical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={'max_depth':(3,4,5,6,7,8,9,10), \n",
    "            'min_samples_leaf':(1,5,10,15,20,25)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(estimator=model, param_grid=parameters, scoring='accuracy', n_jobs=-1, cv=10, verbose=True, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(features,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.score(test_data,test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00012-799c0cd0-1cd0-4545-9c87-3895ed7db600",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "f987f61ef11b1ea7dc68c68720320a2cc7aaf71cbcbc17a0ce3f164f72c78491",
    "execution_millis": 68,
    "execution_start": 1621190620982,
    "source_hash": "29ae7853",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now let's go on to building a logistic model. You've seen this before, a regression technique\n",
    "# applied to categorical data, and we're going to use the sklearn LogisticRegression\n",
    "# class to build our model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Building the classifier is straight forward, we just create a new instance of the LogisticRegression\n",
    "# class then call the fit() method passing in our features we wish to train on and our labels\n",
    "# which we want to predict.\n",
    "\n",
    "# For this first model we'll pass in all of the observations and all columns except for the \n",
    "# target which is the outcome_categorical column.\n",
    "features=training_df.drop('outcome_categorical', axis='columns')\n",
    "target=training_df['outcome_categorical']\n",
    "\n",
    "clf=LogisticRegression()\n",
    "reg=clf.fit(features,target)\n",
    "\n",
    "# Now let's print out the R squared value of this model on the same data\n",
    "reg.score(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00014-cbbf127b-7946-46cf-b001-c1e1c61a5d8a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "etc_hash": "5197efea6ed33737857eaa90c1b3198688594f8f481f916260b2c0a5d66ad19b",
    "execution_millis": 9,
    "execution_start": 1621190623136,
    "source_hash": "4dd4ab50",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# So, that's a pretty bad model. Let's see how well it works on our test data.\n",
    "# Specifically, let's take a look at the accuracy, or the number of correct \n",
    "# predictions we can make. We can import an accuracy_score helper function \n",
    "# from sklearn.metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Now form a variable which has the correct labels and one which has the predictions\n",
    "labels=testing_df['outcome_categorical']\n",
    "predictions=reg.predict(testing_df.drop('outcome_categorical', axis='columns'))\n",
    "\n",
    "# And let's take a look at our results\n",
    "print( f\"score {accuracy_score(labels,predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "69b52525-17a3-47ce-a8a2-a2e26f4c3971",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
